---
id: security
title: 보안 계층
sidebar_position: 3
---

# 보안 아키텍처

Private AI 시스템을 위한 다층 보안 접근 방식입니다.

## 계층 1: 네트워크 격리

```
┌─────────────────────────────────────┐
│  Headscale Private Network          │
│  - WireGuard (ChaCha20, Curve25519) │
│  - 기기별 공개 키 인증               │
│  - 사전 승인된 기기만 허용           │
└─────────────────────────────────────┘
```

## 계층 2: 컨테이너 격리

```
┌─────────────────────────────────────┐
│  컨테이너 런타임                     │
│  - no-new-privileges               │
│  - cap-drop ALL                     │
│  - 지정된 폴더만 접근               │
└─────────────────────────────────────┘
```

## 계층 3: 데이터 격리

```
┌─────────────────────────────────────┐
│  로컬 LLM (Ollama)                  │
│  - 완전 로컬 추론                   │
│  - 외부 API 호출 없음               │
│  - 모델 가중치 한 번만 다운로드      │
└─────────────────────────────────────┘
```

## 기기 인증 정책

### 허용된 기기 등록

1. Headscale 서버에서 사전 인증 키 생성
2. 새 기기에 Tailscale 설치 + 키로 인증
3. Headscale에서 기기 승인
4. ACL로 접근 범위 제한

### ACL (접근 제어 목록) 예시

```json
{
  "acls": [
    {
      "action": "accept",
      "src": ["group:trusted"],
      "dst": ["*:*"]
    }
  ],
  "groups": {
    "group:trusted": ["user1", "user2"]
  },
  "hosts": {
    "openclaw-server": "100.64.0.1",
    "ollama-server": "100.64.0.2"
  }
}
```

## 데이터 저장 위치

| 데이터 | 위치 | 암호화 |
|-------|------|--------|
| 메시지 | 로컬 기기 | 선택적 |
| 설정 | `~/.openclaw/` | 아니오 |
| 세션 | `~/.openclaw/sessions/` | 아니오 |
| LLM 모델 | `~/.ollama/models/` | 아니오 |
| VPN 키 | `/var/lib/tailscale/` | 예 |

## 장애 대응

### Headscale 서버 다운

- 기존 연결은 유지 (P2P)
- 새 기기 등록 불가
- 해결: 서버 재시작 또는 백업 사용

### Ollama 응답 없음

- OpenClaw가 대체 모델 사용 (설정된 경우)
- 또는 에러 반환
- 해결: `ollama serve` 재시작

### VPN 연결 끊김

- 메시징 중단
- 로컬 작업은 계속 가능
- 해결: Tailscale 재연결
